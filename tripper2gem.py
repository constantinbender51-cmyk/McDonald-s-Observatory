import ccxt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import time

def fetch_binance_data(symbol='BTC/USDT', timeframe='1d', start_date='2018-01-01T00:00:00Z'):
    """
    Fetches historical OHLCV data from Binance using CCXT.
    Handles pagination to get full history.
    """
    print(f"Fetching {timeframe} data for {symbol} starting from {start_date}...")
    exchange = ccxt.binance({
        'rateLimit': 1200,
        'enableRateLimit': True
    })
    
    # Convert start date to timestamp
    since = exchange.parse8601(start_date)
    all_ohlcv = []
    
    while True:
        try:
            # Binance usually allows fetching 1000 candles max per request
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since, limit=1000)
            
            if not ohlcv:
                break
                
            all_ohlcv.extend(ohlcv)
            
            # Update 'since' to be the timestamp of the last candle + 1ms to avoid duplicates
            last_timestamp = ohlcv[-1][0]
            since = last_timestamp + 1
            
            # Break if we've reached current time (approximate check)
            if last_timestamp >= exchange.milliseconds() - 24 * 60 * 60 * 1000:
                break
                
            print(f"Fetched {len(all_ohlcv)} candles so far...")
            
        except Exception as e:
            print(f"Error fetching data: {e}")
            break

    df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df.set_index('timestamp', inplace=True)
    
    print(f"Total candles fetched: {len(df)}")
    return df

def calculate_indicators(df):
    """
    Calculates MACD, Signal Line, Stochastic RSI, and Change Percentages.
    """
    print("Calculating technical indicators...")
    
    # 1. Price and Volume Change Percentages (Current Day)
    df['pct_change'] = df['close'].pct_change()
    df['vol_change'] = df['volume'].pct_change()
    
    # 2. MACD (12, 26, 9)
    exp1 = df['close'].ewm(span=12, adjust=False).mean()
    exp2 = df['close'].ewm(span=26, adjust=False).mean()
    df['macd'] = exp1 - exp2
    df['signal_line'] = df['macd'].ewm(span=9, adjust=False).mean()
    
    # 3. Stochastic RSI (14)
    # First calculate RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    
    # Then Stoch RSI
    min_rsi = rsi.rolling(window=14).min()
    max_rsi = rsi.rolling(window=14).max()
    df['stoch_rsi'] = (rsi - min_rsi) / (max_rsi - min_rsi)
    
    return df

def create_features_and_target(df, window=28, prediction_horizon=7):
    """
    Creates lag features for the last 'window' days and the prediction target.
    """
    print(f"Creating lag features ({window} days) and target ({prediction_horizon} days ahead)...")
    
    features = []
    
    # Create 28-day history features for Price Change and Volume Change
    for i in range(1, window + 1):
        # Lagged Price Change
        col_name_p = f'pct_change_lag_{i}'
        df[col_name_p] = df['pct_change'].shift(i)
        features.append(col_name_p)
        
        # Lagged Volume Change
        col_name_v = f'vol_change_lag_{i}'
        df[col_name_v] = df['vol_change'].shift(i)
        features.append(col_name_v)
    
    # Add current technical indicators to features
    features.extend(['macd', 'signal_line', 'stoch_rsi'])
    
    # Create Target: 1 if Close in 7 days > Current Close, else 0
    # We shift -7 to bring the future value to the current row for training
    future_close = df['close'].shift(-prediction_horizon)
    df['target'] = (future_close > df['close']).astype(int)
    
    # Drop NaNs generated by lags (at start) and target shifting (at end)
    df_clean = df.dropna()
    
    return df_clean, features

def train_and_evaluate(df, feature_cols):
    """
    Trains Logistic Regression and evaluates on the last 20% of data.
    """
    X = df[feature_cols]
    y = df['target']
    
    # Split data: Shuffle=False is CRITICAL for time series
    # We take the last 20% as the test set
    split_point = int(len(df) * 0.80)
    
    X_train = X.iloc[:split_point]
    X_test = X.iloc[split_point:]
    y_train = y.iloc[:split_point]
    y_test = y.iloc[split_point:]
    
    print(f"Training set size: {len(X_train)}")
    print(f"Test set size: {len(X_test)}")
    
    # Standard Scaling (Important for Logistic Regression convergence and weight interpretation)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Initialize and Train
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X_train_scaled, y_train)
    
    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Evaluate
    accuracy = accuracy_score(y_test, y_pred)
    
    print("\n" + "="*40)
    print(f"Prediction Accuracy (Next 7 Days Direction): {accuracy:.4f}")
    print("="*40)
    print("\nClassification Report:\n")
    print(classification_report(y_test, y_pred))
    
    return model, accuracy

if __name__ == "__main__":
    # 1. Fetch Data
    # Ensure you have internet access. 
    # If rate limits hit, the script will handle basic waiting, but might take a minute.
    df = fetch_binance_data(symbol='BTC/USDT', start_date='2018-01-01T00:00:00Z')
    
    if not df.empty:
        # 2. Calculate Indicators
        df = calculate_indicators(df)
        
        # 3. Create Features (28 days lookback) and Target (7 days lookahead)
        df_model, feature_columns = create_features_and_target(df, window=28, prediction_horizon=7)
        
        # 4. Train and Test
        train_and_evaluate(df_model, feature_columns)
    else:
        print("No data fetched. Please check your connection or API availability.")
